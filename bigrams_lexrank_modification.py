# -*- coding: utf-8 -*-
"""Bigrams_lexrank_modification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FoQNz7CMXxG3v3p5CGaXwES9N_iUyI4A
"""

import nltk
nltk.download('punkt')
nltk.download('stopwords')

from nltk.stem import PorterStemmer
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from nltk.corpus import stopwords
import re

from nltk import tokenize

from nltk.tokenize import word_tokenize

from nltk.tokenize import punkt

from itertools import combinations

from nltk import ngrams



#text = open('/content/drive/MyDrive/ML/test_data.txt','r', encoding='utf-8')
with open('drive/MyDrive/ML/text.txt','r', encoding='utf-8') as f:
  text = f.read()
  text = text.replace('\n','')
text

stop_words = set(stopwords.words('english'))

word_tokens = word_tokenize(text)
 
filtered_text = [w.lower() for w in word_tokens if not w.lower() in stop_words and w.isalnum()]
 
print(word_tokens)
print(filtered_text)

words_dict = {}
for word in filtered_text:
  if word in words_dict.keys():
    words_dict[word] += 1
  else:
    words_dict[word] = 1

words_dict

words_dict = dict(sorted(words_dict.items(), key=lambda item: item[1],reverse=True))
top_words = list(words_dict.keys())[:10]
list(top_words)

top_combinations = combinations(top_words, 2)
list(top_combinations)

combinations_text = combinations(words_dict.keys(), 2)
#len(list(combinations_text))
list(combinations_text)

{k:filtered_text.count(k) for k in top_words}

combinations_dict = {}

for combination_word in combinations_text:
  if combination_word in combinations_dict:
    combinations_dict[combination_word] += 1
  else:
    combinations_dict[combination_word] = 1

combinations_dict

stop_words = set(stopwords.words('english'))

lines = text
output = []
for line in lines:
  output.append(line.strip())

print(lines)

sents = tokenize.sent_tokenize(lines)

sents

for i,_ in enumerate(sents):
  sents[i] = sents[i].split()
  for word in list(sents[i]):
    if word.lower() in stop_words or not word.isalnum():
      sents[i].remove(word)
for i,_ in enumerate(sents):
  sents[i] = ' '.join(sents[i])
print(sents)

list(ngrams(sents[10].split(), 2))

sents_dict =  {i : [] for i in range(len(sents))}
sents_dict

bigrams_freq = {}
for key in sents_dict.keys():
  try: 
    bigrams = list(ngrams(sents[key].split(),2))
  except Exception:
    continue
  sents_dict[key] = bigrams
  for bigram in bigrams:
    if bigram in bigrams_freq.keys():
      bigrams_freq[bigram] += 1
    else:
       bigrams_freq[bigram] = 1

bigrams_freq

bigrams_freq = dict(sorted(bigrams_freq.items(), key=lambda item: item[1],reverse=True))
top_bigrams = list(bigrams_freq.keys())[:10]
list(top_bigrams)

top_sents ={}
for bigram in top_bigrams:
  bigram =  ' '.join(list(bigram))
  for sent in sents:
    if bigram in sent: 
      if sent in top_sents.keys():
       top_sents[sent] += 1
      else:
        top_sents[sent]  =  1
print(list(top_sents.keys())[:10])

top_sents = dict(sorted(top_sents.items(), key=lambda item: item[1],reverse=True))
print(top_sents)

print(list(top_sents.keys())[:5])